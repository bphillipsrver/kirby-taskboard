name: Daily Database Backup

on:
  schedule:
    # Run daily at 2 AM UTC (9 PM EST / 10 PM EDT)
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        ref: backups
        
    - name: Setup Git
      run: |
        git config user.name "Backup Bot"
        git config user.email "backup@kirby-taskboard.local"
        
    - name: Install jq
      run: sudo apt-get install -y jq
        
    - name: Create backup from live database
      env:
        API_KEY: ${{ secrets.BACKUP_API_KEY }}
        API_URL: ${{ secrets.API_URL }}
      run: |
        # Create backup directory with date
        DATE=$(date +%Y-%m-%d)
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        mkdir -p "backups/$DATE"
        
        # Trigger backup API and get file URLs
        echo "ðŸ“¡ Triggering backup API..."
        curl -s -H "x-api-key: $API_KEY" "$API_URL/api/backup" > backup-response.json
        
        # Check if backup file exists and has content
        if [ ! -s backup-response.json ]; then
          echo "âŒ Backup failed - no response or empty file"
          cat backup-response.json
          exit 1
        fi
        
        echo "âœ… Backup API response received"
        cat backup-response.json
        
        # Parse the response to get file URLs using jq
        SQL_PATH=$(cat backup-response.json | jq -r '.files.sql // empty')
        JSON_PATH=$(cat backup-response.json | jq -r '.files.json // empty')
        TASK_COUNT=$(cat backup-response.json | jq -r '.taskCount // 0')
        
        if [ -z "$SQL_PATH" ]; then
          echo "âŒ Failed to parse backup response - SQL path is empty"
          cat backup-response.json
          exit 1
        fi
        
        echo "âœ… Backup API returned files:"
        echo "   SQL: $SQL_PATH"
        echo "   JSON: $JSON_PATH"
        echo "   Tasks: $TASK_COUNT"
        
        # Download the backup files
        echo "ðŸ“¥ Downloading backup files..."
        curl -s "$API_URL$SQL_PATH" > "backups/$DATE/backup-${TIMESTAMP}.sql"
        curl -s "$API_URL$JSON_PATH" > "backups/$DATE/tasks-${TIMESTAMP}.json"
        
        # Save metadata
        cp backup-response.json "backups/$DATE/metadata-${TIMESTAMP}.json"
        
        # Verify downloads
        SQL_SIZE=$(stat -c%s "backups/$DATE/backup-${TIMESTAMP}.sql" 2>/dev/null || echo "0")
        JSON_SIZE=$(stat -c%s "backups/$DATE/tasks-${TIMESTAMP}.json" 2>/dev/null || echo "0")
        
        if [ "$SQL_SIZE" -gt 0 ]; then
          echo "âœ… SQL backup downloaded ($SQL_SIZE bytes)"
        else
          echo "âŒ SQL backup download failed or empty"
          exit 1
        fi
        
        if [ "$JSON_SIZE" -gt 0 ]; then
          echo "âœ… JSON backup downloaded ($JSON_SIZE bytes)"
        else
          echo "âŒ JSON backup download failed or empty"
          exit 1
        fi
        
        # Clean up old backups (keep only last 30 days)
        echo "ðŸ§¹ Cleaning up old backups..."
        find backups -type d -name "202*" -mtime +30 -exec rm -rf {} + 2>/dev/null || true
        find backups -type f -name "*.sql" -mtime +30 -delete 2>/dev/null || true
        find backups -type f -name "*.json" -mtime +30 -delete 2>/dev/null || true
        
        echo "âœ… Backup process complete"
        
    - name: Commit and push backup
      run: |
        DATE=$(date +%Y-%m-%d)
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        
        # Check if there are changes
        if [ -z "$(git status --porcelain)" ]; then
          echo "No changes to commit"
          exit 0
        fi
        
        git add -A
        git commit -m "Daily backup: $DATE

        - SQL dump: backup-${TIMESTAMP}.sql
        - JSON export: tasks-${TIMESTAMP}.json
        - Tasks backed up: $(find backups -name '*.json' -type f | wc -l) files
        
        Automated backup from Render database"
        
        git push origin backups
        echo "âœ… Backup pushed to GitHub"
